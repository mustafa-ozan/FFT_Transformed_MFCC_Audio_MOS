{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1OGbXI6cYUM4IfVUMla5JXrwOo-tV97TF","timestamp":1765696858257},{"file_id":"1A_hU4A8Va-w0sHX94WiDsjKQPfXUyysz","timestamp":1765685454250}],"authorship_tag":"ABX9TyO+y+SR7zylNHRbrmvinofF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install torchcodec\n","\n","# Install the necessary system library for torchaudio backends (SoX)\n","!sudo apt-get update\n","!sudo apt-get install -y sox libsox-dev libsox-fmt-all\n","\n","# Verify installation (optional)\n","!sox --version"],"metadata":{"id":"F1eQAePyCS4O"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aS_PVGdW7uoR"},"outputs":[],"source":["# 14.12.2025\n","# Feature extractor for VoiceMOS 2022 data\n","#\n","# Author : Mustafa Ozan Duman\n","\n","import numpy as np\n","import torch\n","import torchaudio\n","import torch.nn as nn\n","import torchaudio.transforms as T\n","import pandas as pd\n","import os\n","from google.colab import drive\n","from tqdm.notebook import tqdm\n","\n","# --- Step 0: Google Drive Setup and Directory Definitions ---\n","\n","# 1. Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define base paths according to your place\n","DRIVE_BASE_PATH = #'/content/drive/MyDrive/BUU_PHD_THESIS/datasets_with_MOS/main/main/' # original path is given here\n","\n","WAV_DIR = os.path.join(DRIVE_BASE_PATH, 'DATA/wav')\n","MOS_LISTS_DIR = os.path.join(DRIVE_BASE_PATH, 'DATA/sets')\n","\n","# Define output feature directories (using /content/ for faster I/O)\n","OUTPUT_BASE_PATH = #'/content/drive/MyDrive/BUU_PHD_THESIS/VoiceMOS_2022_features' # original path is comment out\n","\n","TRAIN_OUTPUT_DIR = os.path.join(OUTPUT_BASE_PATH, 'VoiceMOS_2022_train_data_features')\n","TEST_OUTPUT_DIR = os.path.join(OUTPUT_BASE_PATH, 'VoiceMOS_2022_test_data_features')\n","VAL_OUTPUT_DIR = os.path.join(OUTPUT_BASE_PATH, 'VoiceMOS_2022_validation_data_features')\n","\n","# Create output directories if they don't exist\n","os.makedirs(TRAIN_OUTPUT_DIR, exist_ok=True)\n","os.makedirs(TEST_OUTPUT_DIR, exist_ok=True)\n","os.makedirs(VAL_OUTPUT_DIR, exist_ok=True)\n","print(\"Output directories created in /content/.\")\n","\n","# Define the MOS list files\n","MOS_LIST_FILES = ['train_mos_list.txt', 'test_mos_list.txt', 'val_mos_list.txt']\n","\n","\n","# --- Feature Extraction Functions (Adapted for Global Max Time Steps) ---\n","\n","# Step 1: Extract MFCC features and zero-padding\n","def extract_features(audio_path, max_time_steps):\n","    \"\"\"\n","    Extract MFCC features (2D matrix) and zero-pad to match the GLOBAL max_time_steps.\n","    \"\"\"\n","    try:\n","        waveform, sample_rate = torchaudio.load(audio_path, normalize=True)\n","    except Exception as e:\n","        print(f\"Error loading {audio_path}: {e}\")\n","        return None # Return None on load failure\n","\n","    mfcc_transform = T.MFCC(\n","        sample_rate=sample_rate,\n","        n_mfcc=40,\n","        melkwargs={\"n_fft\": 400, \"hop_length\": 160, \"n_mels\": 40}\n","    )\n","    mfcc = mfcc_transform(waveform)\n","\n","    # Transpose to (time_steps, n_mfcc)\n","    mfcc = mfcc.squeeze(0).transpose(0, 1)  # (time_steps, n_mfcc)\n","\n","    # Handle single frame case\n","    if mfcc.dim() == 1:\n","        mfcc = mfcc.unsqueeze(0)\n","\n","    # Zero-padding to match the max_time_steps\n","    time_steps, n_mfcc = mfcc.shape\n","\n","    # Convert to numpy for padding and ensure float32 consistency\n","    mfcc_np = mfcc.numpy()\n","\n","    if time_steps < max_time_steps:\n","        # Pad with zeros along the time axis (first dimension)\n","        padding = max_time_steps - time_steps\n","        mfcc_np = np.pad(mfcc_np, ((0, padding), (0, 0)), mode='constant')\n","\n","    elif time_steps > max_time_steps:\n","        # Truncate if a file somehow exceeds the calculated global max (shouldn't happen\n","        # but included for robustness)\n","        mfcc_np = mfcc_np[:max_time_steps, :]\n","\n","    return np.array(mfcc_np, dtype=np.float32)\n","\n","\n","# Step 2: Apply FFT to MFCC matrix (Unchanged, operates on padded matrix)\n","def apply_2d_fft(mfcc_matrix):\n","    \"\"\"\n","    Apply 2D FFT to the MFCC matrix, shift the result, take the first quarter,\n","    and then standardize the matrix before returning.\n","    \"\"\"\n","    # Apply 2D FFT\n","    fft_result = np.fft.fft2(mfcc_matrix)\n","    fft_result_shifted = np.fft.fftshift(fft_result)\n","    fft_result_abs = np.abs(fft_result_shifted)\n","    rows, cols = fft_result_abs.shape\n","    row_mid = rows // 2\n","    col_mid = cols // 2\n","    fft_result_quarter = fft_result_abs[:row_mid, :col_mid]\n","\n","    # Handle cases where the dimensions are odd (keep the middle row/column if needed)\n","    if rows % 2 != 0:\n","        fft_result_quarter = np.vstack([\n","            fft_result_quarter,\n","            fft_result_abs[row_mid:row_mid + 1, :col_mid]  # Keep the middle row\n","        ])\n","    if cols % 2 != 0:\n","        fft_result_quarter = np.hstack([\n","            fft_result_quarter,\n","            fft_result_abs[:row_mid, col_mid:col_mid + 1]  # Keep the middle column\n","        ])\n","\n","    # Standardize the result\n","    std_dev = np.std(fft_result_quarter)\n","    if std_dev != 0:\n","        fft_result_standardized = (fft_result_quarter - np.mean(fft_result_quarter)) / std_dev\n","    else:\n","        fft_result_standardized = fft_result_quarter - np.mean(fft_result_quarter)\n","\n","    # print(f\"Shape of saved fft_result_standardized array: {fft_result_standardized.shape}\")\n","    return fft_result_standardized\n","\n","\n","\n","\n","# Step 3: Custom Data Reader function\n","def load_mos_list(mos_list_path):\n","    \"\"\"\n","    Loads utterance IDs and MOS scores from the custom text file format.\n","    Returns a pandas DataFrame.\n","    \"\"\"\n","    df = pd.read_csv(\n","        mos_list_path,\n","        header=None,\n","        names=['utt_id', 'mos_score'],\n","        sep=','\n","    )\n","    return df\n","\n","# Step 4: Save Features Function\n","def save_features(mfcc_list, mos_scores, utt_ids, output_dir):\n","    \"\"\"\n","    Save extracted MFCC features and MOS scores into .npy files in the specified directory.\n","    \"\"\"\n","\n","    mfcc_file = os.path.join(output_dir, \"mfcc_features.npy\")\n","    mos_file = os.path.join(output_dir, \"mos_scores.npy\")\n","    utt_ids_file = os.path.join(output_dir, \"utt_ids.npy\")\n","\n","    # The output features will have a uniform shape due to global padding and FFT\n","    mfcc_array = np.array(mfcc_list)\n","    mos_array = np.array(mos_scores)\n","    utt_ids_array = np.array(utt_ids)\n","\n","    # Save arrays\n","    np.save(mfcc_file, mfcc_array)\n","    np.save(mos_file, mos_array)\n","    np.save(utt_ids_file, utt_ids_array)\n","\n","    print(f\"\\nSaved MFCCs to {mfcc_file}\")\n","    print(f\"Shape of saved MFCC array: {mfcc_array.shape}\")\n","    print(f\"Shape of saved MOS array: {mos_array.shape}\")\n","    print(\"---\")\n","\n","\n","# --- Main Execution ---\n","\n","# Global counter for failed attempts to limit excessive output\n","global_failures = 0\n","MAX_PRINT_FAILURES = 5 # Only print errors for the first 5 failed files\n","\n","def find_global_max_time_step():\n","    \"\"\"\n","    Scans all files across all splits to find the single largest time step,\n","    with detailed debugging output for the first few failures.\n","    \"\"\"\n","    global global_failures\n","    global_failures = 0\n","\n","    print(\"\\n--- Phase 1: Scanning all files to find GLOBAL Max Time Steps ---\")\n","\n","    all_files_to_scan = []\n","\n","    # 1. Collect all utterance IDs from all MOS list files\n","    for file_name in MOS_LIST_FILES:\n","        mos_list_path = os.path.join(MOS_LISTS_DIR, file_name)\n","        # Assuming load_mos_list is defined correctly elsewhere\n","        df = load_mos_list(mos_list_path)\n","        all_files_to_scan.extend(df['utt_id'].tolist())\n","\n","    print(f\"Total files to scan: {len(all_files_to_scan)}\")\n","\n","    global_max_time_steps = 0\n","\n","    # 2. Iterate through all files and determine the maximum length\n","    for utt_id in tqdm(all_files_to_scan, desc=\"Finding Global Max\"):\n","        audio_path = os.path.join(WAV_DIR, utt_id)\n","\n","        try:\n","            # We only load and calculate the MFCC shape, not the full extraction\n","            waveform, sample_rate = torchaudio.load(audio_path, normalize=True)\n","\n","            # Use the defined MFCC transform parameters\n","            mfcc_transform = T.MFCC(\n","                sample_rate=sample_rate,\n","                n_mfcc=40,\n","                melkwargs={\"n_fft\": 400, \"hop_length\": 160, \"n_mels\": 40}\n","            )\n","            mfcc = mfcc_transform(waveform)\n","            mfcc = mfcc.squeeze(0).transpose(0, 1) # (time_steps, n_mfcc)\n","            time_steps = mfcc.shape[0]\n","\n","            global_max_time_steps = max(global_max_time_steps, time_steps)\n","\n","        except Exception as e:\n","            # --- DEBUGGER PRINTS ADDED HERE ---\n","            if global_failures < MAX_PRINT_FAILURES:\n","                print(f\"\\n[DEBUG FAILURE #{global_failures + 1}]\")\n","                print(f\"File: {audio_path}\")\n","                print(f\"Error Type: {type(e).__name__}\")\n","                print(f\"Error Message: {e}\")\n","\n","            global_failures += 1\n","            pass # Continue to the next file\n","\n","    if global_max_time_steps == 0 and global_failures > 0:\n","        print(f\"\\n--- SCAN FAILED ---\")\n","        print(f\"Global max time steps is 0. Failed to load {global_failures} files.\")\n","        print(\"This confirms a loading issue. Check 'torchaudio' dependencies (like SoX).\")\n","\n","    return global_max_time_steps\n","\n","\n","def process_all_splits(global_max_time_steps):\n","    \"\"\"\n","    Processes all splits using the determined global_max_time_steps.\n","    \"\"\"\n","    print(f\"\\n--- Phase 2: Processing All Data using GLOBAL Max Time Steps ({global_max_time_steps}) ---\")\n","\n","    # Define file names and their corresponding output directories\n","    data_splits = [\n","        ('train', 'train_mos_list.txt', TRAIN_OUTPUT_DIR),\n","        ('test', 'test_mos_list.txt', TEST_OUTPUT_DIR),\n","        ('val', 'val_mos_list.txt', VAL_OUTPUT_DIR),\n","    ]\n","\n","    for split_name, file_name, output_dir in data_splits:\n","        print(f\"\\n**Starting processing for {split_name.upper()} split**\")\n","        mos_list_path = os.path.join(MOS_LISTS_DIR, file_name)\n","        df = load_mos_list(mos_list_path)\n","\n","        mfcc_list = []\n","        mos_scores = []\n","        utt_ids = []\n","\n","        # Iterate and extract features with padding\n","        for index, row in tqdm(df.iterrows(), total=len(df), desc=f\"Extracting {split_name}\"):\n","            utt_id = row['utt_id']\n","            mos = row['mos_score']\n","            audio_path = os.path.join(WAV_DIR, utt_id)\n","\n","            # Extract MFCCs and pad to global_max_time_steps\n","            mfcc = extract_features(audio_path, global_max_time_steps)\n","\n","            if mfcc is not None:\n","                # Apply FFT to the now fixed-size MFCC matrix\n","\n","                # print(f\"Shape of mfcc array before fft: {mfcc.shape}\")\n","\n","                mfcc_fft = apply_2d_fft(mfcc)\n","\n","                # print(f\"Shape of mfcc array before fft: {mfcc.shape}\")\n","\n","                # Store the transformed MFCC and MOS score\n","                mfcc_list.append(mfcc_fft)\n","                mos_scores.append(mos)\n","                utt_ids.append(utt_id)\n","            else:\n","                print(f\"Failed to process {utt_id}, skipping.\")\n","\n","        print(f\"Successfully processed {len(mfcc_list)} files for {split_name}.\")\n","\n","        # Save results for the current split\n","        save_features(mfcc_list, mos_scores, utt_ids, output_dir)\n","\n","\n","if __name__ == '__main__':\n","    # Execute Phase 1: Find the Global Maximum\n","    global_max = find_global_max_time_step()\n","    # global_max = 4575 # found in my trial\n","    # Execute Phase 2: Process All Splits using the Global Maximum\n","    if global_max > 0:\n","        process_all_splits(global_max)\n","    else:\n","        print(\"Error: Could not determine a valid global max time step. Check data paths.\")"]}]}